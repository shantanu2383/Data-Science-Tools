{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM29nZumB5DIO7LhCWQ99r4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shantanu2383/Data-Science-Tools/blob/main/Factiva_PDF_Scraper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H-HlR5h8zuAm"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount your Google Drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyPDF2\n",
        "import PyPDF2\n",
        "import re\n",
        "import pandas as pd\n",
        "import glob\n",
        "import os\n",
        "\n",
        "# Define the regex patterns\n",
        "word_count_pattern = r'(\\d{1,3}(?:,\\d{3})*|\\d+) words'\n",
        "date_pattern = r'\\d{1,2} [A-Z][a-z]+ \\d{4}(?!\\d{2}:\\d{2})'\n",
        "publisher_pattern = r'(?<=\\n)' + date_pattern + r'\\n(?:\\d{2}:\\d{2}\\n)?(\\w+(?:\\s+\\w+){0,3})'\n",
        "\n",
        "# Initialize an empty list to store the rows of data\n",
        "data = []\n",
        "\n",
        "for file_name in os.listdir(pdf_folder):\n",
        "    if file_name.endswith(\".pdf\"):\n",
        "        # Open the PDF file\n",
        "        with open(os.path.join(pdf_folder, file_name), 'rb') as pdf_file:\n",
        "\n",
        "          # Create a PDF reader object\n",
        "          pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
        "\n",
        "          # Get the number of pages in the PDF file\n",
        "          num_pages = len(pdf_reader.pages)\n",
        "\n",
        "          # Loop through all pages and extract text\n",
        "          page_text = []\n",
        "          for page_num in range(num_pages):\n",
        "              page_obj = pdf_reader.pages[page_num]\n",
        "              text = page_obj.extract_text()\n",
        "              page_text.append(text)\n",
        "\n",
        "          # Close the PDF file\n",
        "          pdf_file.close()\n",
        "\n",
        "          # Join all text from all pages into one long string\n",
        "          full_text = ' '.join(page_text)\n",
        "\n",
        "          # Split the text into articles\n",
        "          separator_pattern = r'Document [a-zA-Z0-9]{5,}'\n",
        "          articles_text = re.split(separator_pattern, full_text)[1:]\n",
        "\n",
        "          # Iterate through each article and extract the desired information\n",
        "          for article in articles_text:\n",
        "              # Extract the word count\n",
        "              word_count_match = re.search(word_count_pattern, article)\n",
        "              word_count = word_count_match.group(1) if word_count_match else 'not found'\n",
        "\n",
        "              # Extract the date\n",
        "              date_match = re.search(date_pattern, article)\n",
        "              date = date_match.group() if date_match else 'not found'\n",
        "\n",
        "              # Extract the publisher\n",
        "              publisher_match = re.search(publisher_pattern, article, flags=re.MULTILINE)\n",
        "              publisher = publisher_match.group(1) if publisher_match else 'not found'\n",
        "\n",
        "              # Append the data to the list\n",
        "              data.append([article, word_count, date, publisher])\n",
        "\n",
        "# Create a DataFrame from the data\n",
        "df = pd.DataFrame(data, columns=['article', 'word_count', 'date', 'publisher'])\n"
      ],
      "metadata": {
        "id": "Mkanl2c21pqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(filepath+ 'FACTIVA_ARTICLES.csv', index=False)\n"
      ],
      "metadata": {
        "id": "LJ4qvLVM1wC0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}