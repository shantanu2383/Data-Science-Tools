{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPdogcj+tBT8wVwDBsOfmNc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shantanu2383/Data-Science-Tools/blob/main/Article_URL_Scraper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HvO364ua2DJY"
      },
      "outputs": [],
      "source": [
        "#WAYBACK SCRAPER\n",
        "#Function accesses article webpage using the Wayback Archive Machine and scrapes article text where article is available\n",
        "\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from requests.adapters import HTTPAdapter\n",
        "from requests.packages.urllib3.util.retry import Retry\n",
        "\n",
        "def scrape_article_from_wayback_machine(url):\n",
        "    session = requests.Session()\n",
        "    retries = Retry(total=5, backoff_factor=0.3, status_forcelist=[429, 500, 502, 503, 504])\n",
        "    adapter = HTTPAdapter(max_retries=retries)\n",
        "    session.mount('http://', adapter)\n",
        "    session.mount('https://', adapter)\n",
        "\n",
        "    wayback_machine_url = f\"http://archive.org/wayback/available?url={url}\"\n",
        "    response = session.get(wayback_machine_url)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        json_response = response.json()\n",
        "        snapshot_url = json_response.get(\"archived_snapshots\", {}).get(\"closest\", {}).get(\"url\")\n",
        "\n",
        "        if snapshot_url:\n",
        "            snapshot_response = session.get(snapshot_url)\n",
        "            if snapshot_response.status_code == 200:\n",
        "                soup = BeautifulSoup(snapshot_response.content, \"html.parser\")\n",
        "                article_element = soup.find(\"article\")\n",
        "\n",
        "                if article_element:\n",
        "                    article_text = article_element.get_text()\n",
        "                    return article_text\n",
        "                else:\n",
        "                    return \"Article element not found in the snapshot\"\n",
        "            else:\n",
        "                return \"Failed to retrieve snapshot from Wayback Machine\"\n",
        "        else:\n",
        "            return \"Snapshot not found in Wayback Machine\"\n",
        "    else:\n",
        "        return \"Failed to query Wayback Machine API\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#URL SCRAPER\n",
        "#Function accesses article directly using article webpage and scrapes article text where article is available\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def scrape_article_text(url, timeout=15):\n",
        "    try:\n",
        "        response = requests.get(url, timeout=timeout)\n",
        "        response.raise_for_status()\n",
        "    except requests.exceptions.Timeout as e:\n",
        "        print(f\"Timeout scraping {url}: {e}\")\n",
        "        return \"\"\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error scraping {url}: {e}\")\n",
        "        return \"\"\n",
        "\n",
        "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "    article = soup.find(\"article\")\n",
        "    if article is not None:\n",
        "        text = article.get_text()\n",
        "    else:\n",
        "        text = \"\"\n",
        "    return text"
      ],
      "metadata": {
        "id": "xk39XN4S2I0o"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}